I need to integrate the LexML Brasil API into my project to search for transport-related legislation. LexML uses the SRU (Search/Retrieve via URL) protocol version 1.1/1.2 with CQL (Contextual Query Language).

API SPECIFICATIONS:
- Base URL: https://www.lexml.gov.br/busca/SRU
- Protocol: SRU 1.1/1.2
- Query Language: CQL
- Response Format: XML (Dublin Core metadata)
- No authentication required

REQUIRED PARAMETERS:
- operation=searchRetrieve (mandatory)
- version=1.1 (mandatory)
- query=[CQL query] (mandatory)
- maximumRecords=100 (optional, default 20)
- startRecord=1 (optional, for pagination)

CQL QUERY FORMAT:
- Basic: field operator value
- Fields: urn, date, subject, tipoDocumento, autoridade, localidade
- Operators: any (contains), all (all words), = (exact)
- Example: "urn any transporte and autoridade=Federal"

REQUIREMENTS:
1. Create a Python class that searches for all transport-related terms (list provided in transport_terms.txt)
2. Implement proper error handling and retry logic
3. Include pagination to get all results
4. Parse XML responses and extract: URN, title, date, document type, description, URL
5. Include the web scraping method as a fallback when API returns errors (code provided in fallback_scraper.py)
6. Save results to CSV with deduplication
7. Create a summary report

The API often returns 500 errors, so the fallback scraper is essential. The system should automatically switch to web scraping when the API fails.

Please create a robust solution that tries the API first, then falls back to web scraping if needed.